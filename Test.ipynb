{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "API Key loaded: sk_eb8601680d2e1ed56e2972dcd253a26240317c9bcfbd08ce\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Load environment variables from .env file\n",
                "load_dotenv()\n",
                "\n",
                "# Access the variable\n",
                "api_key = os.getenv(\"ElevenLabsAPI_KEY\")\n",
                "print(f\"API Key loaded: {api_key}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "expected argument value expression (2758773733.py, line 8)",
                    "output_type": "error",
                    "traceback": [
                        "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mclient.speech_to_text.convert(model_id=)\u001b[39m\n                                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected argument value expression\n"
                    ]
                }
            ],
            "source": [
                "from elevenlabs import ElevenLabs\n",
                "\n",
                "client = ElevenLabs(\n",
                "    base_url=\"https://api.elevenlabs.io\",\n",
                "    api_key=api_key\n",
                ")\n",
                "\n",
                "client.speech_to_text.convert(model_id=)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "language_code='eng' language_probability=1.0 text=\"With a soft and whispery American accent, I'm the ideal choice for creating ASMR content, meditative guides, or adding an intimate feel to your narrative projects.\" words=[SpeechToTextWordResponseModel(text='...With', start=0.079, end=0.259, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=0.259, end=0.28, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='a', start=0.28, end=0.459, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=0.459, end=0.5, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='soft', start=0.5, end=1.039, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=1.039, end=1.22, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=1.22, end=1.419, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=1.419, end=1.459, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='whispery', start=1.459, end=2.119, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=2.119, end=2.199, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='American', start=2.2, end=2.719, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=2.719, end=2.84, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='accent,', start=2.84, end=4.139, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=4.139, end=4.279, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"I'm\", start=4.279, end=4.46, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=4.46, end=4.539, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='the', start=4.539, end=4.599, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=4.599, end=4.759, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='ideal', start=4.759, end=5.099, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=5.099, end=5.239, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='choice', start=5.239, end=5.719, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=5.719, end=6.119, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='for', start=6.119, end=6.199, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=6.199, end=6.299, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='creating', start=6.299, end=6.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=6.879, end=7.019, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='ASMR', start=7.019, end=7.739, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=7.739, end=7.879, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='content,', start=7.879, end=8.5, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=8.5, end=9.099, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='meditative', start=9.099, end=9.64, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=9.64, end=9.72, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='guides,', start=9.72, end=11.3, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=11.3, end=11.34, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='or', start=11.34, end=11.5, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=11.5, end=11.579, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='adding', start=11.579, end=11.88, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=11.88, end=11.979, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='an', start=11.979, end=12.079, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=12.079, end=12.199, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='intimate', start=12.199, end=12.579, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=12.579, end=12.699, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='feel', start=12.699, end=13.14, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=13.14, end=13.179, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=13.179, end=13.26, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=13.26, end=13.319, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='your', start=13.319, end=13.399, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=13.399, end=13.48, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='narrative', start=13.48, end=13.859, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=13.859, end=13.94, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='projects.', start=13.94, end=14.779, type='word', speaker_id='speaker_0', logprob=0.0, characters=None)] channel_index=None additional_formats=None transcription_id='O2va22Ja2dcV0FtnvKHT' entities=None\n"
                    ]
                }
            ],
            "source": [
                "# example.py\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from io import BytesIO\n",
                "import requests\n",
                "from elevenlabs.client import ElevenLabs\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "elevenlabs = ElevenLabs(\n",
                "  api_key=api_key,\n",
                ")\n",
                "\n",
                "audio_url = (\n",
                "    \"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3\"\n",
                ")\n",
                "response = requests.get(audio_url)\n",
                "audio_data = BytesIO(response.content)\n",
                "\n",
                "transcription = elevenlabs.speech_to_text.convert(\n",
                "    file=audio_data,\n",
                "    model_id=\"scribe_v2\", # Model to use\n",
                "    tag_audio_events=True, # Tag audio events like laughter, applause, etc.\n",
                "    language_code=\"eng\", # Language of the audio file. If set to None, the model will detect the language automatically.\n",
                "    diarize=True, # Whether to annotate who is speaking\n",
                ")\n",
                "\n",
                "print(transcription)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
